{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of HW3 Part A_B student version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nsi5pHEHXIN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1664b23-3552-4c99-a24d-b1f7cb3c93dd"
      },
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf 6864-hw3a\n",
        "rm -rf MIT_*\n",
        "git clone https://github.com/luohongyin/MIT_6.864_Hw3_Data.git\n",
        "mv MIT_6.864_Hw3_Data /content/6864-hw3a\n",
        "cp /content/6864-hw3a/tree.py ./span_tree.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MIT_6.864_Hw3_Data'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY7OK7jKHN4C"
      },
      "source": [
        "# MIT 6.864 HW3 Part A\n",
        "\n",
        "In this lab, we will practice parsing sentences on a slot-filling corpus. We will conduct on a semantic parsing corpus.  \n",
        "The data is from this paper(just take a look at Figure 1): https://arxiv.org/pdf/1810.07942.pdf  \n",
        "As you can see from the figure, the purpose of this task is to understand what are the users intents from a query in plain text.  \n",
        "The end goal is to decode a tree structure with semantic tags as nodes. For example:   \n",
        "[IN:GET_EVENT whats there to do [SL:DATE_TIME this weekend ] ]  \n",
        "Note that the brackets [some span of text] indicate this span is a sub-tree.  \n",
        "\n",
        "In Part A, we formulate the problem as a simple classification problem, the input to the classifier will be (text, span) and the output will be the label of that span.  \n",
        "In Part B, we will implement a CKY decoding algorithm to decode the final tree based on the classifier we trained in Part A.\n",
        "\n",
        "We did pre-processing to enable CKY-style decoding for you. (Code is at https://github.mit.edu/tianxing/mit_6864_hw3_202003 if you are interested)  The data now are all binary-trees.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIOkqXIoHN4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2eb6826-95bd-4adb-8398-4eb9c2a46bac"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from span_tree import *\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#device = \"cpu\"\n",
        "device = torch.device(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQzMXTeHN4M"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "We apply a model that learns the parsing structures in 4 steps.\n",
        "\n",
        "1. Enumerate all possible spans of a sentence\n",
        "2. Generating word and span embeddings\n",
        "3. Learning span classifications\n",
        "4. Decoding a tree structure using the classification distributions of spans\n",
        "\n",
        "We go through this process step by step.\n",
        "\n",
        "## Data Processing\n",
        "\n",
        "The very first step of the project is to load the corpus, building the vocabulary, span label set, and span indexes. We enumerate every node of a tree with depth first search (DFS)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUOkaRgqRbW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAauBjH1d9Up"
      },
      "source": [
        "def tree_dfs(node, span_list, label_dict, mode):\n",
        "    # print(node)\n",
        "    if len(node.children) == 0:\n",
        "        # print(type(node))\n",
        "        assert(type(node) == Token)\n",
        "        cur_span = (node.index, node.index + 1)\n",
        "        cur_label = label_dict['Token']\n",
        "        span_list.append([cur_span, cur_label])\n",
        "        return span_list, label_dict\n",
        "        \n",
        "    cur_span = node.get_token_span()\n",
        "    cur_label = node.label\n",
        "    if node.label in label_dict:\n",
        "        cur_label = label_dict[node.label]\n",
        "    elif mode == 'train':\n",
        "        cur_label = len(label_dict)\n",
        "        label_dict[node.label] = cur_label\n",
        "    else:\n",
        "        cur_label = label_dict['UNK']\n",
        "    span_list.append([cur_span, cur_label])\n",
        "    \n",
        "    if len(node.children) > 1: #if only has one child, we will ignore the Token label, otherwise the token span would have two conflicting labels\n",
        "        for child in node.children:\n",
        "            # --------- Your code (hint: only need one single line) --------- #\n",
        "            span_list, label_dict = tree_dfs(child, span_list, label_dict, mode)\n",
        "            # --------- Your code ends --------- #\n",
        "    \n",
        "    return span_list, label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42LFAdiqeCCE"
      },
      "source": [
        "Then we go through the corpus and construct the vocab dictionary, the label dictionary, and the span label list. Note that we just adding new words and labels to the dictionaries while building the training set. Unseen words or labels in valid and test set are marked as unknown (UNK)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHZ4qUgoHN4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9f7b225c-8ae6-4911-eb2d-8dabcdac2d4a"
      },
      "source": [
        "def process_line(line, vocab_dict, label_dict, mode):\n",
        "    '''\n",
        "    Processing a line in the corpus.\n",
        "    line format: Sentence \\t Sentence_Tree \\n\n",
        "    \n",
        "    Example:\n",
        "        'what is the shortest way home\\t\n",
        "        [IN:GET_DIRECTIONS what [SUB is [SUB the [SUB shortest [SUB way [SL:DESTINATION home ] ] ] ] ] ]\\n'\n",
        "    \n",
        "    Inputs:\n",
        "    vocab_dict: vocab dictionary {word: word_index, ...}\n",
        "    labels_dict: label dictionary {label: label_index, ...}\n",
        "    '''\n",
        "    s, s_tree = line.strip().split('\\t')\n",
        "    words = s.split(' ')\n",
        "    word_ids = []\n",
        "    for word in words:\n",
        "        if word in vocab_dict:\n",
        "            word_ids.append(vocab_dict[word])\n",
        "        elif mode == 'train':\n",
        "            word_ids.append(len(vocab_dict))\n",
        "            vocab_dict[word] = len(vocab_dict)\n",
        "        else:\n",
        "            word_ids.append(vocab_dict['UNK'])\n",
        "    \n",
        "    tree = Tree(s_tree)\n",
        "    span_list = []\n",
        "    span_list, label_dict = tree_dfs(tree.root.children[0], span_list, label_dict, mode)\n",
        "    return word_ids, span_list, vocab_dict, label_dict\n",
        "\n",
        "def process_corpus(corpus_path, mode, vocab_dict=None, label_dict=None):\n",
        "    lines = open(corpus_path).readlines()\n",
        "    if not vocab_dict:\n",
        "        vocab_dict = {'UNK': 0}\n",
        "    if not label_dict:\n",
        "        label_dict = {'UNK': 0, 'Token': 1, 'None': 2}\n",
        "    corpus = []\n",
        "    sent_spans = []\n",
        "    for line in lines:\n",
        "        word_ids, span_list, vocab_dict, label_dict = process_line(line, vocab_dict, label_dict, mode)\n",
        "        corpus.append(word_ids)\n",
        "        sent_spans.append(span_list)\n",
        "    return corpus, sent_spans, vocab_dict, label_dict\n",
        "\n",
        "corpus_train, spans_train, vocab_dict, label_dict = process_corpus('/content/6864-hw3a/train.txt', 'train')\n",
        "corpus_valid, spans_valid, _, _ = process_corpus('/content/6864-hw3a/valid.txt', 'eval',\n",
        "                                                 vocab_dict=vocab_dict, label_dict=label_dict)\n",
        "corpus_test,  spans_test, _, _  = process_corpus('/content/6864-hw3a/test.txt', 'eval',\n",
        "                                                 vocab_dict=vocab_dict, label_dict=label_dict)\n",
        "\n",
        "num_words = len(vocab_dict)\n",
        "num_labels = len(label_dict)\n",
        "\n",
        "print('Number of different words: {}'.format(num_words))\n",
        "print('Number of different labels: {}'.format(num_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different words: 8626\n",
            "Number of different labels: 147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j_0UKnEHN4R"
      },
      "source": [
        "## Defining the Neural Networks\n",
        "\n",
        "### Sentence Encoding\n",
        "\n",
        "We use a Bi-directional LSTM for sentence encoding. We build a sentence encoder with a embedding layer and a Bi-directional LSTM layer.\n",
        "\n",
        "- Input: word indices [batch_size, sentence_length]\n",
        "- Output: word embeddings [batch_size, sentence_length, hidden_size]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTq0SpbfHN4S"
      },
      "source": [
        "class SentEnc(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_words, num_layers, hidden_size, dropout=0):\n",
        "        super(SentEnc, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_words, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers,\n",
        "                           batch_first=True, dropout=dropout, bidirectional=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # --------- Your code --------- #\n",
        "        outputs, _ = self.lstm(self.embedding(x))\n",
        "        # --------- Your code ends --------- #\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em12BpkGHN4X"
      },
      "source": [
        "### Span Encoding\n",
        "\n",
        "Given the LSTM outputs, we generate the span embeddings with the span indices.\n",
        "\n",
        "- Input: word embeddings [sentence_length, hidden_size], span indices [num_span, 2]\n",
        "- Output: span embeddings [num_span, hidden_size]\n",
        "\n",
        "We generate a span embedding by concatenate the word embeddings of the first and last words of a span. For example, if a span starts from the i-th word and ends at the j-th word, our span embedding would be\n",
        "\n",
        "[h_i^T; h_j^T]^T,\n",
        "\n",
        "where h_i stands for the Bi-LSTM output of the i-th word.\n",
        "\n",
        "In pytorch, Given the hidden states h[0], h[1], ..., h[n], where\n",
        "```\n",
        "h[i].size() = [1, k]\n",
        "```\n",
        "the embedding of span (i, j) is\n",
        "```\n",
        "span_ij = torch.cat([h[i], h[j]], dim=1)\n",
        "span_ij.size() = [1, 2 * k]\n",
        "```\n",
        "Please complete the following function for generating span embeddings.\n",
        "\n",
        "Inputs:\n",
        "- word_embeddings (LSTM outputs) [n_words, hidden_size]\n",
        "- Span indices [n_spans, 2]\n",
        "\n",
        "Outputs:\n",
        "- span embeddings [n_spans, hidden_size * 2]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afGE-9pZHN4Z"
      },
      "source": [
        "def get_span_embeddings(word_embeddings, span_indices):\n",
        "    # --------- Your code --------- #\n",
        "    start_span = torch.index_select(word_embeddings, 1, span_indices[:, 0])\n",
        "    end_span = torch.index_select(word_embeddings, 1, span_indices[:, 1] - 1)\n",
        "    span_embeddings = torch.cat([start_span, end_span], 2)\n",
        "    span_embeddings = span_embeddings.squeeze(0)\n",
        "    #print(span_embeddings.size())\n",
        "    return span_embeddings\n",
        "    # --------- Your code ends --------- #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmDK0xKfHN4g"
      },
      "source": [
        "### Tag Prediction\n",
        "\n",
        "We build a Classifier that puts the neural models together. The classifier takes word and span indices as inputs, and predict span labels by calculating word embeddings, span embeddings, and label logits. we will predict the tag of the spans with a linear classifier.\n",
        "\n",
        "- Inputs: word indices: [batch_size, num_words]\n",
        "- Outputs: span predictions: [num_spans, num_labels]\n",
        "\n",
        "Please implement the forward function following the 3 steps:\n",
        "1. Generate the word embeddings by processing the input sentences with the LSTM sentence encoder.\n",
        "2. Apply dropout on word embeddings.\n",
        "3. Calculate span embeddings with function get_span_embeddings().\n",
        "4. Calculate label logits with the linear layer defined as follow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtWAptvBHN4i"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_words, num_labels, num_layers, hidden_size, dropout=0):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.sent_enc = SentEnc(num_words, num_layers, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(4 * hidden_size, num_labels)\n",
        "    \n",
        "    def forward(self, x, span_indices):\n",
        "        # --------- Your code --------- #\n",
        "        output = self.dropout(self.sent_enc(x))\n",
        "        output = get_span_embeddings(output, span_indices)\n",
        "        logits = self.linear(output)\n",
        "        # --------- Your code ends --------- #\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VYVg6RHN4o"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "With all neural models already defined, we are implementing the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B82dn5UhHN4p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6dd1a4fa-cf7c-46a5-ceb0-453261e778ff"
      },
      "source": [
        "#For decoding, we add some random spans and label them as \"None\"\n",
        "def add_none_span(word_list, span_list, label_dict, all=False):\n",
        "    num_words = len(word_list)\n",
        "    num_labeled_span = len(span_list)\n",
        "    labeled_span_set = set([span for span, label in span_list])\n",
        "    none_spans = []\n",
        "    for i in range(num_words):\n",
        "        for j in range(i + 1, num_words):\n",
        "            if (i, j) not in labeled_span_set:\n",
        "                none_spans.append([(i, j), label_dict['None']])\n",
        "    if not all:\n",
        "        k = min(num_labeled_span, len(none_spans))\n",
        "        sampled_none_spans = random.sample(none_spans, k)\n",
        "    else:\n",
        "        sampled_none_spans = none_spans\n",
        "    return span_list + sampled_none_spans\n",
        "\n",
        "print('Using device: {}'.format(device))\n",
        "\n",
        "# --------- Your code --------- #\n",
        "# There's no code here, just remeber you can tune these hyper-parameters!\n",
        "# --------- Your code ends --------- #\n",
        "batch_size = 1\n",
        "num_layers = 3\n",
        "hidden_size = 200\n",
        "lr = 0.05\n",
        "num_epochs = 4 #Be aware of over-fitting!\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "dropout = 0.25\n",
        "\n",
        "classifier = Classifier(num_words, num_labels, num_layers, hidden_size, dropout)\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "classifier = classifier.to(device)\n",
        "classifier.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    classifier.train()\n",
        "    for i in range(len(corpus_train)):\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print('Epoch {} Batch {}'.format(epoch, i))\n",
        "        \n",
        "        cur_spans = add_none_span(corpus_train[i], spans_train[i], label_dict)\n",
        "        \n",
        "        sent_inputs  = torch.Tensor([corpus_train[i]]).long().to(device)\n",
        "        span_indices = torch.Tensor([x[0] for x in cur_spans]).long().to(device)\n",
        "        span_labels  = torch.Tensor([x[1] for x in cur_spans]).long().to(device)\n",
        "        \n",
        "        # --------- Your code --------- #\n",
        "        pred_labels = classifier(sent_inputs, span_indices)\n",
        "        #print(pred_labels.size())\n",
        "        #print(span_labels.size())\n",
        "        loss = loss_fn(pred_labels, span_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        classifier.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "        # --------- Your code ends --------- #\n",
        "    print('Epoch {}, train loss={}'.format(epoch, total_loss / len(corpus_train)))\n",
        "\n",
        "    total_loss = 0\n",
        "    classifier.eval()\n",
        "    for i in range(len(corpus_valid)):\n",
        "        #if i % 10000 == 0:\n",
        "        #    print('Epoch {} Batch {}'.format(epoch, i))\n",
        "        cur_spans = add_none_span(corpus_valid[i], spans_valid[i], label_dict)\n",
        "        \n",
        "        sent_inputs  = torch.Tensor([corpus_valid[i]]).long().to(device)\n",
        "        span_indices = torch.Tensor([x[0] for x in cur_spans]).long().to(device)\n",
        "        span_labels  = torch.Tensor([x[1] for x in cur_spans]).long().to(device)\n",
        "        \n",
        "        # --------- Your code --------- #\n",
        "        valid_labels = classifier(sent_inputs, span_indices)\n",
        "        loss = loss_fn(valid_labels, span_labels)\n",
        "        total_loss += loss.item()\n",
        "        # --------- Your code ends --------- #\n",
        "    print('Epoch {}, valid loss={}'.format(epoch, total_loss / len(corpus_valid)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 0 Batch 0\n",
            "Epoch 0 Batch 1000\n",
            "Epoch 0 Batch 2000\n",
            "Epoch 0 Batch 3000\n",
            "Epoch 0 Batch 4000\n",
            "Epoch 0 Batch 5000\n",
            "Epoch 0 Batch 6000\n",
            "Epoch 0 Batch 7000\n",
            "Epoch 0 Batch 8000\n",
            "Epoch 0 Batch 9000\n",
            "Epoch 0 Batch 10000\n",
            "Epoch 0 Batch 11000\n",
            "Epoch 0 Batch 12000\n",
            "Epoch 0 Batch 13000\n",
            "Epoch 0 Batch 14000\n",
            "Epoch 0 Batch 15000\n",
            "Epoch 0 Batch 16000\n",
            "Epoch 0 Batch 17000\n",
            "Epoch 0 Batch 18000\n",
            "Epoch 0 Batch 19000\n",
            "Epoch 0 Batch 20000\n",
            "Epoch 0 Batch 21000\n",
            "Epoch 0 Batch 22000\n",
            "Epoch 0 Batch 23000\n",
            "Epoch 0 Batch 24000\n",
            "Epoch 0 Batch 25000\n",
            "Epoch 0 Batch 26000\n",
            "Epoch 0 Batch 27000\n",
            "Epoch 0 Batch 28000\n",
            "Epoch 0 Batch 29000\n",
            "Epoch 0 Batch 30000\n",
            "Epoch 0 Batch 31000\n",
            "Epoch 0, train loss=0.21042825932904624\n",
            "Epoch 0, valid loss=0.10209970946307001\n",
            "Epoch 1 Batch 0\n",
            "Epoch 1 Batch 1000\n",
            "Epoch 1 Batch 2000\n",
            "Epoch 1 Batch 3000\n",
            "Epoch 1 Batch 4000\n",
            "Epoch 1 Batch 5000\n",
            "Epoch 1 Batch 6000\n",
            "Epoch 1 Batch 7000\n",
            "Epoch 1 Batch 8000\n",
            "Epoch 1 Batch 9000\n",
            "Epoch 1 Batch 10000\n",
            "Epoch 1 Batch 11000\n",
            "Epoch 1 Batch 12000\n",
            "Epoch 1 Batch 13000\n",
            "Epoch 1 Batch 14000\n",
            "Epoch 1 Batch 15000\n",
            "Epoch 1 Batch 16000\n",
            "Epoch 1 Batch 17000\n",
            "Epoch 1 Batch 18000\n",
            "Epoch 1 Batch 19000\n",
            "Epoch 1 Batch 20000\n",
            "Epoch 1 Batch 21000\n",
            "Epoch 1 Batch 22000\n",
            "Epoch 1 Batch 23000\n",
            "Epoch 1 Batch 24000\n",
            "Epoch 1 Batch 25000\n",
            "Epoch 1 Batch 26000\n",
            "Epoch 1 Batch 27000\n",
            "Epoch 1 Batch 28000\n",
            "Epoch 1 Batch 29000\n",
            "Epoch 1 Batch 30000\n",
            "Epoch 1 Batch 31000\n",
            "Epoch 1, train loss=0.09105519053570851\n",
            "Epoch 1, valid loss=0.079767666207198\n",
            "Epoch 2 Batch 0\n",
            "Epoch 2 Batch 1000\n",
            "Epoch 2 Batch 2000\n",
            "Epoch 2 Batch 3000\n",
            "Epoch 2 Batch 4000\n",
            "Epoch 2 Batch 5000\n",
            "Epoch 2 Batch 6000\n",
            "Epoch 2 Batch 7000\n",
            "Epoch 2 Batch 8000\n",
            "Epoch 2 Batch 9000\n",
            "Epoch 2 Batch 10000\n",
            "Epoch 2 Batch 11000\n",
            "Epoch 2 Batch 12000\n",
            "Epoch 2 Batch 13000\n",
            "Epoch 2 Batch 14000\n",
            "Epoch 2 Batch 15000\n",
            "Epoch 2 Batch 16000\n",
            "Epoch 2 Batch 17000\n",
            "Epoch 2 Batch 18000\n",
            "Epoch 2 Batch 19000\n",
            "Epoch 2 Batch 20000\n",
            "Epoch 2 Batch 21000\n",
            "Epoch 2 Batch 22000\n",
            "Epoch 2 Batch 23000\n",
            "Epoch 2 Batch 24000\n",
            "Epoch 2 Batch 25000\n",
            "Epoch 2 Batch 26000\n",
            "Epoch 2 Batch 27000\n",
            "Epoch 2 Batch 28000\n",
            "Epoch 2 Batch 29000\n",
            "Epoch 2 Batch 30000\n",
            "Epoch 2 Batch 31000\n",
            "Epoch 2, train loss=0.0583687430451415\n",
            "Epoch 2, valid loss=0.07851546378546942\n",
            "Epoch 3 Batch 0\n",
            "Epoch 3 Batch 1000\n",
            "Epoch 3 Batch 2000\n",
            "Epoch 3 Batch 3000\n",
            "Epoch 3 Batch 4000\n",
            "Epoch 3 Batch 5000\n",
            "Epoch 3 Batch 6000\n",
            "Epoch 3 Batch 7000\n",
            "Epoch 3 Batch 8000\n",
            "Epoch 3 Batch 9000\n",
            "Epoch 3 Batch 10000\n",
            "Epoch 3 Batch 11000\n",
            "Epoch 3 Batch 12000\n",
            "Epoch 3 Batch 13000\n",
            "Epoch 3 Batch 14000\n",
            "Epoch 3 Batch 15000\n",
            "Epoch 3 Batch 16000\n",
            "Epoch 3 Batch 17000\n",
            "Epoch 3 Batch 18000\n",
            "Epoch 3 Batch 19000\n",
            "Epoch 3 Batch 20000\n",
            "Epoch 3 Batch 21000\n",
            "Epoch 3 Batch 22000\n",
            "Epoch 3 Batch 23000\n",
            "Epoch 3 Batch 24000\n",
            "Epoch 3 Batch 25000\n",
            "Epoch 3 Batch 26000\n",
            "Epoch 3 Batch 27000\n",
            "Epoch 3 Batch 28000\n",
            "Epoch 3 Batch 29000\n",
            "Epoch 3 Batch 30000\n",
            "Epoch 3 Batch 31000\n",
            "Epoch 3, train loss=0.04277830207287421\n",
            "Epoch 3, valid loss=0.08017361587450286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4ODDfXKHN4s"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "After training the model, we evaluate the classification result.  \n",
        "What we will do is that we treat a tree strcture as a bag of spans, and then compute F-1 score.  \n",
        "You don't need to write any code in this section. But it's good for you to understand what it's doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH5bRW6UHN4t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfe611d5-8c51-44bd-b0da-61464248881e"
      },
      "source": [
        "from itertools import zip_longest\n",
        "from typing import Counter, Dict, Optional\n",
        "import numpy as np\n",
        "\n",
        "class Calculator:\n",
        "    def __init__(self, strict: bool = False) -> None:\n",
        "        self.num_gold_nt: int = 0\n",
        "        self.num_pred_nt: int = 0\n",
        "        self.num_matching_nt: int = 0\n",
        "        self.strict: bool = strict\n",
        "        self.exact_match = []\n",
        "        self.well_form = []\n",
        "\n",
        "    def get_metrics(self):\n",
        "        precision: float = (\n",
        "            self.num_matching_nt / self.num_pred_nt) if self.num_pred_nt else 0\n",
        "        recall: float = (\n",
        "            self.num_matching_nt / self.num_gold_nt) if self.num_gold_nt else 0\n",
        "        f1: float = (2.0 * precision * recall /\n",
        "                     (precision + recall)) if precision + recall else 0\n",
        "        \n",
        "        return {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1,\n",
        "            \"exact_match\": np.mean(self.exact_match),\n",
        "            \"well_form\": np.mean(self.well_form),\n",
        "        }\n",
        "    \n",
        "    def add_instance_span(self, gold_spans, pred_spans):\n",
        "        self.num_gold_nt += len(gold_spans)\n",
        "        self.num_pred_nt += len(pred_spans)\n",
        "        gold_spans = set(gold_spans)\n",
        "        pred_spans = set(pred_spans)\n",
        "        self.num_matching_nt += len(gold_spans & pred_spans)\n",
        "        self.exact_match.append(int(gold_spans == pred_spans))\n",
        "        well_form = True\n",
        "        for s1 in pred_spans: \n",
        "            for s2 in pred_spans:\n",
        "                if s1[0] < s2[0] and s2[0] < s1[1] and s1[1] < s2[1]:\n",
        "                    well_form = False\n",
        "        self.well_form.append(int(well_form))\n",
        "\n",
        "    def add_instance_tree(self, gold_tree: Tree,\n",
        "                     pred_tree: Optional[Tree] = None) -> None:\n",
        "        node_info_gold: Counter = self._get_node_info(gold_tree)\n",
        "        self.num_gold_nt += sum(node_info_gold.values())\n",
        "            \n",
        "        if pred_tree:\n",
        "            node_info_pred: Counter = self._get_node_info(pred_tree)\n",
        "            self.num_pred_nt += sum(node_info_pred.values())\n",
        "            self.num_matching_nt += sum(\n",
        "                (node_info_gold & node_info_pred).values())\n",
        "            self.exact_match.append(int(node_info_gold.keys() == node_info_pred.keys()))\n",
        "            self.well_form.append(1) #we assume the decoded tree is indeed a tree :)\n",
        "        \n",
        "    def _get_node_info(self, tree) -> Counter:\n",
        "        nodes = tree.root.list_nonterminals()\n",
        "        node_info: Counter = Counter()\n",
        "        for node in nodes:\n",
        "            #node_info[(node.label, self._get_span(node))] += 1 #here I change it to only care about the span\n",
        "            node_info[(self._get_span(node))] += 1\n",
        "        return node_info\n",
        "\n",
        "    def _get_span(self, node):\n",
        "        return node.get_flat_str_spans(\n",
        "        ) if self.strict else node.get_token_span()\n",
        "\n",
        "\n",
        "classifier.eval()\n",
        "num_correct = 0.\n",
        "num_spans = 0\n",
        "calc = Calculator(strict=False)\n",
        "\n",
        "for kk in range(len(corpus_test)):\n",
        "    #we will create bag of spans based on our prediction\n",
        "\n",
        "    #cur_spans = add_none_span(corpus_test[i], spans_test[i], label_dict)\n",
        "    cur_spans = spans_test[kk]\n",
        "    cur_spans = [x for x in cur_spans if x[0][1] > x[0][0] + 1] #only test non-terminals\n",
        "    #print(cur_spans)\n",
        "    if len(cur_spans) <= 1: continue\n",
        "    gold_spans = [x[0] for x in cur_spans]\n",
        "\n",
        "    tokens = corpus_test[kk]\n",
        "    cur_len = len(corpus_test[kk])\n",
        "    sent_inputs  = torch.Tensor([tokens]).long().to(device)\n",
        "    all_spans = []\n",
        "    for i in range(cur_len):\n",
        "        for j in range(i + 2, cur_len + 1):\n",
        "            all_spans.append((i,j))\n",
        "    logits = classifier(sent_inputs, torch.Tensor(all_spans).long().to(device))\n",
        "    #logprobs = torch.log(torch.softmax(logits, dim = -1))\n",
        "    \n",
        "    pred_spans = []\n",
        "    for i, span in enumerate(all_spans):\n",
        "        if torch.argmax(logits[i]).item() != 2:\n",
        "            pred_spans.append(span)\n",
        "    \n",
        "    calc.add_instance_span(gold_spans, pred_spans)\n",
        " \n",
        "print(calc.get_metrics())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'precision': 0.87623500663761, 'recall': 0.9848937013072758, 'f1': 0.9273924315049332, 'exact_match': 0.5400825064109711, 'well_form': 0.5649459248522689}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M84DfyR3-ujZ"
      },
      "source": [
        "## Questions:  \n",
        "You don't need to write additional code for the questions. Also, your answer doesn't need to be long.  \n",
        "1.What is the final scores you get? (Our F1 is 0.91) What does well_form and exact_match mean (Please look at our provided code)?\n",
        "\n",
        "2.We generate the word and span embeddings with a bi-directional LSTM. Why is it better than using a uni-directional LSTM?\n",
        "\n",
        "3.Can you suggest one potential method to improve the current algorithm for generating span embeddings? Explain why it is possible to work better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasnfaK4qTfU"
      },
      "source": [
        "# PartB  \n",
        "The remaining will be partB for HW3.  \n",
        "In part B, we will decode a tree based on the classifier trained on part A.  \n",
        "Important hint: You should avoid the \"None\" type during the decoding.  \n",
        "\n",
        "You will be implementing the following simple CYK recursion:  \n",
        "best_score[i,j]=max_k {best_score[i,k]+best_score[k,j]} + max_l {span_dict[(i,j)][l]}  \n",
        "where l is the label of the current span (i,j), and k is the splitting point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHPVa39Fqhhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "4e188599-2ccd-41c1-ba5a-ceb56a87e118"
      },
      "source": [
        "dp_results = []\n",
        "classifier.eval()\n",
        "for kk, line in enumerate(open('/content/6864-hw3a/test.txt', 'r').readlines()):\n",
        "    line = line.strip()\n",
        "    if len(line) < 3: continue\n",
        "    if kk < 10:\n",
        "        print(kk, line)\n",
        "    tokens = corpus_test[kk]\n",
        "    sent_inputs  = torch.Tensor([corpus_test[kk]]).long().to(device)\n",
        "    all_spans = []\n",
        "    for i in range(len(tokens)):\n",
        "        for j in range(i + 1, len(tokens) + 1):\n",
        "            all_spans.append((i,j))\n",
        "    logits = classifier(sent_inputs, torch.Tensor(all_spans).long().to(device))\n",
        "    logprobs = torch.log(torch.softmax(logits, dim = -1))\n",
        "    span_dict = {}\n",
        "    for i, s in enumerate(all_spans): span_dict[s] = logprobs[i] #span dict will map each span (l,r) to its predicted distribution of labels\n",
        "    TOKEN_ID, NULL_ID = 1, 2\n",
        "    best_score, best_split, best_label = {}, {}, {} #we will do dynamic programming to decode a binary tree out of our predictions\n",
        "    \n",
        "    #Think: why do we first iterate the length of the span?\n",
        "    for ll in range(1, len(tokens) + 1): #length of the span\n",
        "        for i in range(0, len(tokens)): #start of the span\n",
        "            if i + ll > len(tokens): break\n",
        "            j = i + ll; cur_span = (i, j)\n",
        "            if j == i + 1:\n",
        "                # --------- Your code --------- #\n",
        "                #use span_dict[cur_span] to update best_label and best_score, be careful, it could either be a TOKEN or something else\n",
        "                cur_best = torch.argmax(span_dict[cur_span]).item()\n",
        "                best_label[cur_span] = cur_best\n",
        "                best_score[cur_span] = span_dict[cur_span][cur_best].item()\n",
        "                best_split[cur_span] = None \n",
        "                # --------- Your code ends --------- #\n",
        "            else:\n",
        "                span_dict[cur_span][NULL_ID] = -100000 #we will never decode a NULL sub-tree\n",
        "                span_dict[cur_span][TOKEN_ID] = -100000 #we will never decode a NULL sub-tree\n",
        "                # --------- Your code --------- #\n",
        "                #try to give the values for best_score/label/split[cur_span]\n",
        "                cur_best = torch.argmax(span_dict[cur_span]).item()\n",
        "                best_label[cur_span] = cur_best\n",
        "                \n",
        "                temp_best = -10000000000\n",
        "                for split in range(i+1, j):\n",
        "                  alter_best = best_score[(i, split)] + best_score[(split, j)]\n",
        "                  if alter_best >= temp_best:\n",
        "                    best_split[cur_span] = split\n",
        "                    temp_best = alter_best\n",
        "\n",
        "                best_score[cur_span] = temp_best + span_dict[cur_span][cur_best].item()\n",
        "                # --------- Your code ends --------- #\n",
        "            #print(cur_span, best_score[cur_span], best_label[cur_span])\n",
        "    dp_results.append((best_score, best_split, best_label))\n",
        "print(len(dp_results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 whats there to do this weekend\t[IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "1 what is a good restaurant for tex mex in austin\t[IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
            "2 where can i see the fireworks tonight\t[IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
            "3 restaurants offering prefixed menus in midtown\t[IN:UNSUPPORTED restaurants [SUB offering [SUB prefixed [SUB menus [SUB in midtown ] ] ] ] ]\n",
            "4 holiday recipes\t[IN:UNSUPPORTED holiday recipes ]\n",
            "5 where should i go dancing this weekend\t[IN:GET_EVENT where [SUB should [SUB i [SUB go [SUB [SL:CATEGORY_EVENT dancing ] [SL:DATE_TIME this weekend ] ] ] ] ] ]\n",
            "6 what is going on this weekend\t[IN:GET_EVENT what [SUB is [SUB going [SUB on [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "7 are there any santa meetings this weekend\t[IN:GET_EVENT are [SUB there [SUB any [SUB [SL:CATEGORY_EVENT santa meetings ] [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "8 what breakfast locations within 5 miles of me open at 6 am\t[IN:UNSUPPORTED what [SUB breakfast [SUB locations [SUB within [SUB 5 [SUB miles [SUB of [SUB me [SUB open [SUB at [SUB 6 am ] ] ] ] ] ] ] ] ] ] ]\n",
            "9 what can i do with my friends tomorrow night\t[IN:GET_EVENT what [SUB can [SUB i [SUB do [SUB with [SUB [SL:ATTENDEE_EVENT--IN:GET_CONTACT [SL:CONTACT_RELATED my ] [SL:TYPE_RELATION friends ] ] [SL:DATE_TIME tomorrow night ] ] ] ] ] ] ]\n",
            "9042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp7gnX87QFog"
      },
      "source": [
        "In the next section, we will construct a tree using the dp results.  \n",
        "Before start doing it, please get yourself a little familiar with the span_tree.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpKRpZEiSNF1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "4b75897e-c1ae-4a67-b60b-8974fd96e6df"
      },
      "source": [
        "import sys\n",
        "inv_label_dict = {}\n",
        "for l in label_dict: inv_label_dict[label_dict[l]] = l\n",
        "#print(inv_label_dict)\n",
        "\n",
        "def get_nodetype(label):\n",
        "    if label.startswith(PREFIX_INTENT):\n",
        "        node = Intent(label)\n",
        "    elif label.startswith(PREFIX_SLOT):\n",
        "        node = Slot(label)\n",
        "    elif label.startswith(PREFIX_SUBTREE):\n",
        "        node = SubTree(label)\n",
        "    else:\n",
        "        print('something wrong with the label!!!', label, l, r)\n",
        "        sys.exit(1)\n",
        "    return node\n",
        "\n",
        "def dfs_build(l, r):\n",
        "    #print('l: ' + str(l))\n",
        "    #print('r: ' + str(r))\n",
        "    if l + 1 == r:\n",
        "        la = best_label[(l,r)]\n",
        "        if la == 1:\n",
        "            return Token(surface_tokens[l], l)\n",
        "        else:\n",
        "            node = get_nodetype(inv_label_dict[la])\n",
        "            node.children = [Token(surface_tokens[l], l)]\n",
        "            node.children[0].parent = node\n",
        "            return node\n",
        "\n",
        "    label = inv_label_dict[best_label[(l, r)]]\n",
        "    node = get_nodetype(label)\n",
        "    \n",
        "    #--- your code --- #\n",
        "    split = best_split[(l, r)]\n",
        "    left_child = dfs_build(l, split)\n",
        "    right_child = dfs_build(split, r)\n",
        "    node.children = [left_child, right_child]\n",
        "    #--- your code ends --- #\n",
        "\n",
        "    for c in node.children:\n",
        "        c.parent = node\n",
        "    \n",
        "    return node\n",
        "\n",
        "pred_trees = []\n",
        "for kk, line in enumerate(open('/content/6864-hw3a/test.txt', 'r').readlines()):\n",
        "    tt = line.strip().split('\\t')\n",
        "    surface_tokens, str_ref_tree = tt[0].split(), tt[1]\n",
        "    if len(line) < 3: continue\n",
        "    tokens = corpus_test[kk]\n",
        "    cur_len = len(tokens)\n",
        "    best_score, best_split, best_label = dp_results[kk]\n",
        "    #print(inv_label_dict[best_label[(0, cur_len)]], best_split[(0, cur_len)])\n",
        "    root = Root()\n",
        "    root.children = [dfs_build(0, cur_len)]\n",
        "    root.children[0].parent = root\n",
        "    tree = Tree('IN:GET_EVENT placeholder') #the string here is just a placeholder\n",
        "    tree.root = root\n",
        "    if kk < 10: #use this info for debugging! Does your tree make sense?\n",
        "        print(kk, line.strip())\n",
        "        print('REF:', str_ref_tree)\n",
        "        print('DEC:', str(tree))\n",
        "        print()\n",
        "    \"\"\" here's some decoding examples we get\n",
        "    0 whats there to do this weekend\t[IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "    REF: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "    DEC: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "\n",
        "    1 what is a good restaurant for tex mex in austin\t[IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "    REF: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "    DEC: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "    2 where can i see the fireworks tonight\t[IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
        "    REF: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
        "    DEC: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB the [SUB fireworks [SL:DATE_TIME tonight ] ] ] ] ] ] ]\n",
        "    \"\"\"\n",
        "    pred_trees.append(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 whats there to do this weekend\t[IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "REF: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "DEC: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "\n",
            "1 what is a good restaurant for tex mex in austin\t[IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
            "REF: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
            "DEC: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
            "\n",
            "2 where can i see the fireworks tonight\t[IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
            "REF: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
            "DEC: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB the [SUB fireworks [SL:DATE_TIME tonight ] ] ] ] ] ] ]\n",
            "\n",
            "3 restaurants offering prefixed menus in midtown\t[IN:UNSUPPORTED restaurants [SUB offering [SUB prefixed [SUB menus [SUB in midtown ] ] ] ] ]\n",
            "REF: [IN:UNSUPPORTED restaurants [SUB offering [SUB prefixed [SUB menus [SUB in midtown ] ] ] ] ]\n",
            "DEC: [IN:UNSUPPORTED restaurants [SUB offering [SUB prefixed [SUB menus [SUB in midtown ] ] ] ] ]\n",
            "\n",
            "4 holiday recipes\t[IN:UNSUPPORTED holiday recipes ]\n",
            "REF: [IN:UNSUPPORTED holiday recipes ]\n",
            "DEC: [IN:GET_EVENT--SL:CATEGORY_EVENT [SL:DATE_TIME holiday ] recipes ]\n",
            "\n",
            "5 where should i go dancing this weekend\t[IN:GET_EVENT where [SUB should [SUB i [SUB go [SUB [SL:CATEGORY_EVENT dancing ] [SL:DATE_TIME this weekend ] ] ] ] ] ]\n",
            "REF: [IN:GET_EVENT where [SUB should [SUB i [SUB go [SUB [SL:CATEGORY_EVENT dancing ] [SL:DATE_TIME this weekend ] ] ] ] ] ]\n",
            "DEC: [IN:GET_EVENT where [SUB should [SUB i [SUB go [SUB [SL:CATEGORY_EVENT dancing ] [SL:DATE_TIME this weekend ] ] ] ] ] ]\n",
            "\n",
            "6 what is going on this weekend\t[IN:GET_EVENT what [SUB is [SUB going [SUB on [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "REF: [IN:GET_EVENT what [SUB is [SUB going [SUB on [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "DEC: [IN:GET_EVENT what [SUB is [SUB going [SUB on [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "\n",
            "7 are there any santa meetings this weekend\t[IN:GET_EVENT are [SUB there [SUB any [SUB [SL:CATEGORY_EVENT santa meetings ] [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "REF: [IN:GET_EVENT are [SUB there [SUB any [SUB [SL:CATEGORY_EVENT santa meetings ] [SL:DATE_TIME this weekend ] ] ] ] ]\n",
            "DEC: [IN:GET_EVENT are [SUB there [SUB any [SUB [SL:NAME_EVENT santa ] [SUB [SL:CATEGORY_EVENT meetings ] [SL:DATE_TIME this weekend ] ] ] ] ] ]\n",
            "\n",
            "8 what breakfast locations within 5 miles of me open at 6 am\t[IN:UNSUPPORTED what [SUB breakfast [SUB locations [SUB within [SUB 5 [SUB miles [SUB of [SUB me [SUB open [SUB at [SUB 6 am ] ] ] ] ] ] ] ] ] ] ]\n",
            "REF: [IN:UNSUPPORTED what [SUB breakfast [SUB locations [SUB within [SUB 5 [SUB miles [SUB of [SUB me [SUB open [SUB at [SUB 6 am ] ] ] ] ] ] ] ] ] ] ]\n",
            "DEC: [IN:UNSUPPORTED what [SUB breakfast [SUB locations [SUB within [SUB 5 [SUB miles [SUB of [SUB me [SUB open [SUB at [SUB 6 am ] ] ] ] ] ] ] ] ] ] ]\n",
            "\n",
            "9 what can i do with my friends tomorrow night\t[IN:GET_EVENT what [SUB can [SUB i [SUB do [SUB with [SUB [SL:ATTENDEE_EVENT--IN:GET_CONTACT [SL:CONTACT_RELATED my ] [SL:TYPE_RELATION friends ] ] [SL:DATE_TIME tomorrow night ] ] ] ] ] ] ]\n",
            "REF: [IN:GET_EVENT what [SUB can [SUB i [SUB do [SUB with [SUB [SL:ATTENDEE_EVENT--IN:GET_CONTACT [SL:CONTACT_RELATED my ] [SL:TYPE_RELATION friends ] ] [SL:DATE_TIME tomorrow night ] ] ] ] ] ] ]\n",
            "DEC: [IN:UNSUPPORTED what [SUB can [SUB i [SUB do [SUB with [SUB my [SUB friends [SUB tomorrow night ] ] ] ] ] ] ] ]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJXGohgsWZCs"
      },
      "source": [
        "Finally, we will compute the F1 score, using the pred_trees.  \n",
        "You don't need to write any code in this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRInPh7IWgbK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5cd9cc6f-cb3f-433b-e133-6b11a2958d96"
      },
      "source": [
        "print(len(pred_trees))\n",
        "#compute the score!\n",
        "labeled_bracketing_scores = Calculator(strict=False)\n",
        "\n",
        "for kk, line in enumerate(open('/content/6864-hw3a/test.txt', 'r').readlines()):\n",
        "    tt = line.strip().split('\\t')\n",
        "    surface_tokens, str_ref_tree = tt[0].split(), tt[1]\n",
        "    if len(line) < 3: continue\n",
        "    tokens = corpus_test[kk]\n",
        "    labeled_bracketing_scores.add_instance_tree(Tree(str_ref_tree), pred_trees[kk])\n",
        "\n",
        "print(labeled_bracketing_scores.get_metrics())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9042\n",
            "{'precision': 0.8922701152815963, 'recall': 0.8862570906192865, 'f1': 0.8892534382294662, 'exact_match': 0.5172528201725282, 'well_form': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvT7-lGzbT2W"
      },
      "source": [
        "Questions (You don't need to write any code for these questions, also, your answer does not need to be very long):  \n",
        "1. What's your final scores? (We get F1 of 0.88) \n",
        "2. Did you notice any common error in your decoded tree comparing to the reference tree? What could be the reason?  \n",
        "3. In the training, we label some random spans without labels as \"None\". How does that help with our decoding?  \n",
        "4. Is it easy to frame the whole problem as a seq2seq task? How would you do it?\n",
        "\n",
        "Recommended Reading (not required, just for interested students):  \n",
        "https://arxiv.org/pdf/1810.07942.pdf  \n",
        "https://www.aclweb.org/anthology/D16-1257/  \n",
        "https://arxiv.org/abs/1412.7449  "
      ]
    }
  ]
}